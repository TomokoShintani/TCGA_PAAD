{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import glob\n",
    "\n",
    "from collections import deque\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tomsh\\\\OneDrive\\\\デスクトップ\\\\研究テーマ\\\\TCGAPAADdata\\\\preprocess_data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() #↓微妙に違う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() #↑微妙に違う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/tomsh/OneDrive/デスクトップ/研究テーマ/TCGAPAADdata/preprocess_data/PAAD_Exp.csv')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(path, \"PAAD_Exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_df = pd.read_csv(\"C:/Users/tomsh/OneDrive/デスクトップ/研究テーマ/TCGAPAADdata/preprocess_data/PAAD_Exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 3000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_df.shape\n",
    "#130人分のデータしかない、、、遺伝子は3000あるけど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEDataset():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X.values)\n",
    "        self.y = torch.Tensor(y.values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx] \n",
    "        #後でdata_loader作るときに、シャッフルした方を\"train\"にして、シャッフルしてないほうを\"test\"にして辞書にする\n",
    "        #キーからデータを取ってこれるようにgetitem関数作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_features, encoding_dim): #encoding_dimはリストで渡す\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, encoding_dim[0])\n",
    "        self.pool1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(encoding_dim[0], encoding_dim[1])\n",
    "        self.pool2 = nn.Dropout(0.5)\n",
    "        print\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Encoder入った\")\n",
    "        #print(\"Encoder入力のxのsizeは:{}\".format(x.shape))\n",
    "        x = torch.tanh(self.fc1(x)) #ReLUだったら入力負の時0になっちゃうからいったんtanhでやってみる。元の論文の原因これReLUにしてたからでは？\n",
    "        x = self.pool1(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.pool2(x)\n",
    "        #print(\"Encoder出力のxのsizeは:{}\".format(x.shape))\n",
    "        #print(\"Encoder出た\")\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoding_dim, input_features):\n",
    "        super().__init__()\n",
    "        self.fc3 = nn.Linear(encoding_dim[1], encoding_dim[0])\n",
    "        self.fc4 = nn.Linear(encoding_dim[0], input_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_features, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_features, encoding_dim)\n",
    "        self.decoder = Decoder(encoding_dim, input_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_func, optimizer, data_loader, n_epochs, fout, device):\n",
    "    #初期化\n",
    "    pkl_queue = deque()\n",
    "    best_loss = 100.0\n",
    "    best_epoch = 0\n",
    "    best_model_weights = model.state_dict()  # state_dict()はtorchの関数\n",
    "    since = time.time()\n",
    "    end = time.time()\n",
    "\n",
    "    print(model, \"\\n\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"EPOCH:{}/{}\".format(epoch+1, n_epochs), end=\"\")\n",
    "        print(\"EPOCH:{}/{}\".format(epoch+1, n_epochs), end=\"\", file=fout)\n",
    "\n",
    "        for phase in [\"train\"]:\n",
    "            model.train(True)\n",
    "\n",
    "            #データの指定\n",
    "            data = data_loader[phase]\n",
    "\n",
    "            #初期化\n",
    "            running_loss = 0\n",
    "\n",
    "            #ミニバッチに対するループ処理\n",
    "            for _, (data_train, target_train) in enumerate(data):\n",
    "                optimizer.zero_grad()\n",
    "                x = data_train.to(device)\n",
    "                y = target_train.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    y_pred = model(x)\n",
    "                    loss = loss_func(y_pred, y)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            epoch_loss = running_loss / (len(data)/len(x))\n",
    "\n",
    "            #最も損失が小さかったモデルを保存\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_weights, \"{}_epoch{}.pkl\".format(fout.name.split(\".txt\")[0], epoch+1))\n",
    "                pkl_queue.append(\"{}_epoch{}.pkl\".format(fout.name.split(\".txt\")[0], epoch+1))\n",
    "\n",
    "                if len(pkl_queue) > 1:\n",
    "                    pkl_file = pkl_queue.popleft()\n",
    "                    os.remove(pkl_file)\n",
    "            \n",
    "            #予測の出力\n",
    "            print(\",{}Loss:{:.4f}, Time:{:.4f}\".format(phase, epoch_loss, time.time()-end), end=\"\")\n",
    "            print(\",{}Loss:{:.4f}, Time:{:.4f}\".format(phase, epoch_loss, time.time()-end), end=\"\", file=fout)\n",
    "            print(\"\\n\", end=\"\")\n",
    "            print(\"\\n\", end=\"\", file=fout)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "    #トレーニング結果の表示\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"\\nTraining completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best loss: {:.4f} at epoch {}\".format(best_loss, best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCH-Lossグラフの描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(file, name):\n",
    "\n",
    "    #トレーニングログファイルの読み込み\n",
    "    df = pd.read_csv(file, header=None, sep=r\"\\s+\")\n",
    "\n",
    "    #線グラフを作成\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(range(len(df)), df.iloc[:, 1])\n",
    "    ax.set_title(f\"MSE loss for \\n{file}\")\n",
    "    ax.set_xlabel(\"EPOCHS\")\n",
    "    ax.set_ylabel(\"MSE loss\")\n",
    "    fig.savefig(f\"{name}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, device):\n",
    "    #初期化\n",
    "    running_mse = 0\n",
    "    preds = []\n",
    "\n",
    "    data = data_loader[\"test\"]\n",
    "    model.eval()\n",
    "\n",
    "    for data_test, target_test in data:\n",
    "        x = data_test.to(device)\n",
    "        y = target_test.to(device)\n",
    "\n",
    "        #予測\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "\n",
    "            #MSEの計算\n",
    "            sq_loss = ((y_pred - y)*(y_pred - y)).sum().data\n",
    "            running_mse += sq_loss\n",
    "\n",
    "            preds.append(y_pred[0])\n",
    "    #予測スコアを表示\n",
    "    preds = np.vstack(preds)\n",
    "    mse = math.sqrt(running_mse / len(data))\n",
    "    print(\"MSE: {}\".format(mse))\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_epochs = 10\n",
    "lr = 0.0008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fileがなかった時に新しくそのディレクトリにfileを作る関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(filename):\n",
    "    if not Path(filename).is_dir():\n",
    "        Path(filename).parents[0].mkdir(parents=True, exist_ok=True)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Encoder(\n",
      "    (fc1): Linear(in_features=3000, out_features=200, bias=True)\n",
      "    (pool1): Dropout(p=0.5, inplace=False)\n",
      "    (fc2): Linear(in_features=200, out_features=50, bias=True)\n",
      "    (pool2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc3): Linear(in_features=50, out_features=200, bias=True)\n",
      "    (fc4): Linear(in_features=200, out_features=3000, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "EPOCH:1/10,trainLoss:10.7981, Time:0.4506\n",
      "EPOCH:2/10,trainLoss:7.1387, Time:0.3823\n",
      "EPOCH:3/10,trainLoss:7.1169, Time:0.3390\n",
      "EPOCH:4/10,trainLoss:7.0969, Time:0.3875\n",
      "EPOCH:5/10,trainLoss:7.1089, Time:0.3433\n",
      "EPOCH:6/10,trainLoss:7.0961, Time:0.3850\n",
      "EPOCH:7/10,trainLoss:7.0942, Time:0.4039\n",
      "EPOCH:8/10,trainLoss:7.1032, Time:0.3763\n",
      "EPOCH:9/10,trainLoss:7.0908, Time:0.4152\n",
      "EPOCH:10/10,trainLoss:7.0973, Time:0.3738\n",
      "\n",
      "Training completed in 0m 4s\n",
      "Best loss: 7.0908 at epoch 8\n",
      "MSE: 204.703205504335\n",
      "[[0.9995261  0.99959964 0.99948174 ... 0.9996484  0.9996797  0.99942505]\n",
      " [0.9995261  0.99959964 0.99948174 ... 0.9996484  0.9996797  0.99942505]\n",
      " [0.9995261  0.99959964 0.99948174 ... 0.9996484  0.9996797  0.99942505]\n",
      " ...\n",
      " [0.9995261  0.99959964 0.99948174 ... 0.9996484  0.9996797  0.99942505]\n",
      " [0.9995261  0.99959964 0.99948174 ... 0.9996484  0.9996797  0.99942505]\n",
      " [0.9995261  0.99959964 0.99948174 ... 0.9996484  0.9996797  0.99942505]]\n",
      "[[-0.93677133 -0.992579    0.99079233 ...  0.93002063  0.9865097\n",
      "  -0.99673057]\n",
      " [-0.9367713  -0.992579    0.99079233 ...  0.9300206   0.9865097\n",
      "  -0.99673057]\n",
      " [-0.9367714  -0.992579    0.99079233 ...  0.9300207   0.9865097\n",
      "  -0.99673057]\n",
      " ...\n",
      " [-0.9367713  -0.992579    0.99079233 ...  0.9300206   0.9865097\n",
      "  -0.99673057]\n",
      " [-0.9367714  -0.992579    0.99079233 ...  0.93002075  0.9865097\n",
      "  -0.99673057]\n",
      " [-0.9367712  -0.99257904  0.99079233 ...  0.9300205   0.9865097\n",
      "  -0.9967306 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12487 (\\N{KATAKANA LETTER DE}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12473 (\\N{KATAKANA LETTER SU}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12463 (\\N{KATAKANA LETTER KU}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12488 (\\N{KATAKANA LETTER TO}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12483 (\\N{KATAKANA LETTER SMALL TU}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12503 (\\N{KATAKANA LETTER PU}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 30740 (\\N{CJK UNIFIED IDEOGRAPH-7814}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 31350 (\\N{CJK UNIFIED IDEOGRAPH-7A76}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12486 (\\N{KATAKANA LETTER TE}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12540 (\\N{KATAKANA-HIRAGANA PROLONGED SOUND MARK}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n",
      "C:\\Users\\tomsh\\AppData\\Local\\Temp\\ipykernel_14296\\753525207.py:12: UserWarning: Glyph 12510 (\\N{KATAKANA LETTER MA}) missing from current font.\n",
      "  fig.savefig(f\"{name}.png\")\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    path = Path.cwd()\n",
    "\n",
    "    #input_dataの読み込み\n",
    "    df = pd.read_csv(Path(path, \"PAAD_Exp.csv\"))\n",
    "    X = df.astype(np.float32)\n",
    "\n",
    "    #load AutoEncoder\n",
    "    model = AutoEncoder(3000, [200, 50])\n",
    "    model = model.to(device)\n",
    "\n",
    "    #dataset 作る\n",
    "    AEdata = AEDataset(X, X)\n",
    "    train_data = DataLoader(AEdata, batch_size=batch_size, shuffle=True)\n",
    "    test_data = DataLoader(AEdata, batch_size=batch_size, shuffle=False)\n",
    "    data_loader = {\"train\": train_data, \"test\" : test_data}\n",
    "\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    #トレーニングログファイルの設定\n",
    "    train_log = \"AE_lr{}_epochs{}_batch{}.txt\".format(lr, n_epochs, batch_size)\n",
    "    fout = open(check_path(str(Path(path, \"AutoEncoder\", train_log))), \"w\") #ログファイルを書き込みモードで開く\n",
    "\n",
    "    #train AutoEncoder\n",
    "    train_model(model, loss_func, optimizer, data_loader, n_epochs, fout, device)\n",
    "\n",
    "    fout.close() #書き込み終了\n",
    "\n",
    "    #train lossの書き出し\n",
    "    plot_loss(str(Path(path, \"AutoEncoder\", train_log)), check_path(str(Path(path, \"AutoEncoder\", f\"epoch{n_epochs}_loss\"))))\n",
    "\n",
    "    #最も性能の良いAEモデルの読み込み\n",
    "    trained_model = glob.glob(str(Path(path, \"AutoEncoder\", \"{}_*.pkl\".format(train_log.split(\".txt\")[0]))))[0]\n",
    "    model.load_state_dict(torch.load(trained_model), strict=False)\n",
    "\n",
    "    #学習済みモデルを用いた予測\n",
    "    decoded_result = eval_model(model, data_loader, device)\n",
    "    print(decoded_result)\n",
    "\n",
    "    #もっともよい学習済みモデルからの特徴抽出\n",
    "    bottleneck_features = model.encoder(torch.Tensor(X.values)).detach().numpy()\n",
    "    print(bottleneck_features)\n",
    "\n",
    "    #低次元特徴量の保存\n",
    "    np.savetxt(check_path(str(Path(path, \"Bottleneck\", f\"epoch{n_epochs}_std_Exp.csv\"))), bottleneck_features, delimiter=\",\")\n",
    "    np.save(check_path(str(Path(path, \"Bottleneck\", f\"epoch{n_epochs}_std_Exp.npy\"))), bottleneck_features)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class LinearReLU(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearReLU, self).__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self,f(x)\n",
    "        return(h)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, bottle_dim)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
